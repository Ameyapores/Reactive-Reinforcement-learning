# Reactive-Reinforcement-learning

A framework to generate reactive behaviours, motivated from Subsumption architecture from 1980s. In our archihtecture each  behaviour is represented as a separate module (Deep network), having direct access to processed sensory information. Each module has an individual specific goal. We use a trivial form of imitation learning, called Behaviour cloning, to train these distinct behaviour layers.

<img src="images/ameya.png" width="400"> 

## Results

Comparison of end-to-end learning vs proposed reactive Reinforcement architecture.

<img src="images/Figure_4.png" width="400"> 
